
# for kafka persistence
# akka.persistence.journal.plugin = "kafka-journal"
# see https://github.com/krasserm/akka-persistence-kafka#configuration-hints

# For redis "persistence", from https://index.scala-lang.org/hootsuite/akka-persistence-redis

akka.persistence.journal.plugin = "akka-persistence-redis.journal"
akka.persistence.snapshot-store.plugin = "akka-persistence-redis.snapshot"

redis {
  host = "localhost"
  host = ${?REDIS_HOST}
  port = 6379
  port = ${?REDIS_PORT}
  # optional
  # password="topsecret"
}

# for sql persistence, from https://index.scala-lang.org/okumin/akka-persistence-sql-async

# akka {
#   persistence {
#     journal.plugin = "akka-persistence-sql-async.journal"
#     snapshot-store.plugin = "akka-persistence-sql-async.snapshot-store"
#   }
# }


cassandra {

  # The contact point to connect to the Cassandra cluster.
  # Accepts a comma-separated string of hosts. Override with -Dcassandra.connection.host.
  connection.host = ${?CASSANDRA_SEEDS}

  # Cassandra thrift port. Defaults to 9160. Override with -Dcassandra.connection.rpc.port.
  connection.rpc.port = ${?CASSANDRA_RPC_PORT}

  # Cassandra native port. Defaults to 9042. Override with -Dcassandra.connection.native.port.
  connection.native.port = ${?CASSANDRA_NATIVE_PORT}

  # Auth: These are expected to be set in the env by chef, etc.
  # The username for authentication. Override with -Dcassandra.auth.username.
  auth.username = ${?CASSANDRA_AUTH_USERNAME}
  # The password for authentication. Override with -Dcassandra.auth.password.
  auth.password = ${?CASSANDRA_AUTH_PASSWORD}

  ## Tuning ##

  # The number of milliseconds to keep unused `Cluster` object before destroying it
  # The duration to keep unused connections open. In millis, defaults to 250.
  # Override with -Dcassandra.connection.keep_alive_ms.
  connection.keep-alive = ${?CASSANDRA_KEEP_ALIVE_MS}

  # The number of times to retry a failed query. Defaults to 10.
  # Override with -Dcassandra.query.retry.count.
  connection.query.retry.count = ${?CASSANDRA_QUEUE_RETRY_COUNT}

  # The initial delay determining how often to try to reconnect to a dead node. In millis, defaults to 1000.
  # Override with -Dcassandra.connection.reconnection_delay_ms.min.
  connection.reconnect-delay.min = ${?CASSANDRA_MIN_RECONNECT_DELAY_MS}

  # The final delay determining how often to try to reconnect to a dead node. In millis, defaults to 60000.
  # Override with -Dcassandra.connection.reconnection_delay_ms.max.
  connection.reconnect-delay.max = ${?CASSANDRA_MAX_RECONNECT_DELAY_MS}

  ## Tuning: use to fine-tune the read process ##

  # To reduce the number of roundtrips to Cassandra, partitions are paged
  # The following properties control the number of partitions and the fetch size:
  # The number of rows fetched per roundtrip. Defaults to 1000.
  # Override with -Dcassandra.input.page.row.size
  read.page.row.size = ${?CASSANDRA_READ_PAGE_ROW_SIZE}

  # How many rows to fetch in a single task. Defaults to 100000.
  # Override with -Dcassandra.input.split.size
  read.split.size = ${?CASSANDRA_READ_SPLIT_SIZE}

  # The consistency level to use when reading. By default, reads are performed at
  # ConsistencyLevel.LOCAL_ONE in order to leverage data-locality and minimize network traffic.
  # Override with -Dcassandra.input.consistency.level.
  read.consistency.level = ${?CASSANDRA_READ_CONSISTENCY_LEVEL}


  ## Tuning: use to fine-tune the saving process ##

  # The maximum number of batches executed in parallel by a single task.
  # Defaults to 5. Override with -Dcassandra.output.concurrent.writes.
  write.concurrent.writes = ${?CASSANDRA_WRITE_CONCURRENT_WRITES}

  # The maximum total size of the batch in bytes; defaults to 64 kB.
  # Override with -Dcassandra.output.batch.size.bytes.
  write.batch.size.bytes = ${?CASSANDRA_WRITE_BATCH_SIZE_BYTES}

  # The number of rows per single batch; default is 'auto' which means the driver
  # will adjust the number of rows based on the amount of data in each row.
  # Override with -Dcassandra.output.batch.size.rows.
  write.batch.size.rows = ${?CASSANDRA_WRITE_BATCH_SIZE_ROWS}

  # The maximum total size of the batch in bytes. Defaults to 64 kB.
  # Override with -D
  write.max-bytes = ${?CASSANDRA_WRITE_MAX_BYTES}

  # By default, writes are performed at ConsistencyLevel.ONE in order to leverage data-locality
  # and minimize network traffic. Override with -Dcassandra.output.consistency.level
  write.consistency.level = ${?CASSANDRA_READ_CONSISTENCY_LEVEL}
}

akka {
  loglevel = "DEBUG"
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  logger-startup-timeout = 60s
  log-dead-letters = off
  log-dead-letters-during-shutdown = off

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      port = 2550
      hostname = "127.0.0.1"
    }
  }

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"

    default-dispatcher {
      # Throughput for default Dispatcher, set to 1 for as fair as possible
      throughput = 10
    }
  }

  cluster {
    log-info = on
    seed-nodes = []
    roles = ["state"]
    gossip-interval = 5s
    publish-stats-interval = 10s
    auto-down-unreachable-after = 10s
    metrics.gossip-interval = 10s
    metrics.collect-interval = 10s
  }
}